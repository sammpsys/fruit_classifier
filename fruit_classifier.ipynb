{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "danish-october",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary modules\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torchvision import models\n",
    "\n",
    "#prepare model for loading\n",
    "vgg_model = models.vgg16(pretrained=True)\n",
    "num_features = vgg_model.classifier[0].in_features\n",
    "new_top = nn.Sequential(nn.Linear(num_features, 8), nn.ReLU(), nn.Linear(8, 2), nn.LogSoftmax(dim=1))\n",
    "vgg_model.classifier = new_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "regional-persian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load model\n",
    "vgg_model.load_state_dict(torch.load('my_fruit_vgg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "leading-soccer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use cuda\n",
    "device = torch.device('cuda')\n",
    "vgg_model = vgg_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "front-pension",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess the camera image; this is needed since the model is trained using RGB\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "mean = 255.0 * np.array([0.485, 0.456, 0.406])\n",
    "stdev = 255.0 * np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "normalize = torchvision.transforms.Normalize(mean, stdev)\n",
    "\n",
    "def preprocess(camera_value):\n",
    "    global device, normalize\n",
    "    x = camera_value\n",
    "    x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n",
    "    x = x.transpose((2, 0, 1))\n",
    "    x = torch.from_numpy(x).float()\n",
    "    x = normalize(x)\n",
    "    x = x.to(device)\n",
    "    x = x[None, ...]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "framed-lodge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a16a9af851ce4e3dad04f55c23c7b8cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\xff\\xdb\\x00C\\x00\\x02\\x01\\x0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#load the camera instance\n",
    "import traitlets\n",
    "from IPython.display import display\n",
    "import ipywidgets\n",
    "from jetbot import Camera, bgr8_to_jpeg\n",
    "\n",
    "camera = Camera.instance(width=224, height=224)#fps=10)\n",
    "image_widget = ipywidgets.Image(format='jpeg', width=400, height=400)\n",
    "\n",
    "camera_link = traitlets.dlink((camera, 'value'), (image_widget, 'value'), transform=bgr8_to_jpeg)\n",
    "\n",
    "display(image_widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "civic-country",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetbot import Robot\n",
    "\n",
    "robot = Robot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "resistant-windsor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import imutils\n",
    "import datetime\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "# avg is used to save a frame of reference picture (background)\n",
    "# the new picture is compared with it to determine where in the picture has changed.\n",
    "avg = None\n",
    "\n",
    "\n",
    "lastMovtionCaptured = datetime.datetime.now()\n",
    "\n",
    "# Fruit detection function\n",
    "def fruitDetect(imgInput):\n",
    "    global avg, lastMovtionCaptured\n",
    "    #get the prediction and normalize to a probability\n",
    "    x = preprocess(imgInput)\n",
    "    y = vgg_model(x)\n",
    "    y = F.softmax(y, dim=1)\n",
    "    \n",
    "    prob_blocked = float(y.flatten()[0])\n",
    "    # Get the current timestamp.\n",
    "    timestamp = datetime.datetime.now()\n",
    "    \n",
    "    # Convert the frame to black and white, which can increase the efficiency of analysis.\n",
    "    gray = cv2.cvtColor(imgInput, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Gaussian blur the frame to avoid misjudgment caused by noise.\n",
    "    gray = cv2.GaussianBlur(gray, (21, 21), 0)\n",
    "\n",
    "    # If the reference frame (background) has not been obtained, create a new one.\n",
    "    if avg is None:\n",
    "        avg = gray.copy().astype(\"float\")\n",
    "        return imgInput\n",
    "\n",
    "    # background update.\n",
    "    cv2.accumulateWeighted(gray, avg, 0.5)\n",
    "    \n",
    "    # Compare the difference between the new frame and the background.\n",
    "    frameDelta = cv2.absdiff(gray, cv2.convertScaleAbs(avg))\n",
    "\n",
    "    # Get the outline of the changed area in the frame.\n",
    "    thresh = cv2.threshold(frameDelta, 5, 255, cv2.THRESH_BINARY)[1]\n",
    "    thresh = cv2.dilate(thresh, None, iterations=2)\n",
    "    \n",
    "    x1,y1,w,h = cv2.boundingRect(thresh)\n",
    "    x2 = x1+w\n",
    "    y2 = y1+h\n",
    "    start = (x1, y1)\n",
    "    end = (x2, y2)\n",
    "    colour = (255, 0, 0)\n",
    "    thickness = 1\n",
    "    \n",
    "    cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "\n",
    "    # There may be more than one area changes in the frame, so you need to use a for loop to get all the contours.\n",
    "    for c in cnts:\n",
    "        # The default here is 30, which is the threshold of the change area. We only analyze the area greater than 800.\n",
    "        # The smaller the value, the more sensitive the motion detection, but it may also detect meaningless noise.\n",
    "        if cv2.contourArea(c) < 30:\n",
    "            continue\n",
    "\n",
    "\n",
    "        # Save the current timestamp to mark the time when the change is detected.\n",
    "        lastMovtionCaptured = timestamp\n",
    "\n",
    "    # In order to avoid the high flickering frequency of drawing elements\n",
    "    # within 0.5 seconds after the motion ends, elements stay.\n",
    "    if (prob_blocked) >0.99 and (timestamp - lastMovtionCaptured).seconds >= 0.5 :\n",
    "        cv2.putText(imgInput,\"Apple found\",(10,30), cv2.FONT_HERSHEY_SIMPLEX, 0.5,(128,255,0),1,cv2.LINE_AA)\n",
    "    elif (prob_blocked) <0.01 and (timestamp - lastMovtionCaptured).seconds >= 0.5:\n",
    "        cv2.putText(imgInput,\"Orange found\",(10,30), cv2.FONT_HERSHEY_SIMPLEX, 0.5,(0,128,255),1,cv2.LINE_AA)\n",
    "    \n",
    "    # Return to the processed frame.\n",
    "    return imgInput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "limiting-active",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this runs the function\n",
    "def execute(change):\n",
    "    global image_widget\n",
    "    image = change['new']\n",
    "    image_widget.value = bgr8_to_jpeg(fruitDetect(image))\n",
    "    \n",
    "execute({'new': camera.value})\n",
    "camera.unobserve_all()\n",
    "camera.observe(execute, names='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "racial-microphone",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run this to stop updating\n",
    "camera.unobserve(execute, names='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "based-emerald",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stop camera instance\n",
    "camera.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adapted-contributor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signal-psychology",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demanding-kazakhstan",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
